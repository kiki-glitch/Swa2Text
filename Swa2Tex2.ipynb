{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P3Aa-Wdc7Rnq",
        "6C5AAUQvbiyk",
        "vdGaA4MTU6nx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiki-glitch/Swa2Text/blob/main/Swa2Tex2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DB4X_g6ovq6"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import * \n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t20ZPt-MU6nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49e8d32-97fa-400a-c86b-768480724b6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVfvp0tkJUGw"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Swahili/data/train/wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOWtGAdRiumj"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "metadata": {
        "id": "24726zD1G18k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP9qdhcRiyUG",
        "outputId": "0ef44011-2036-4fc6-83b7-009121c1ec5c"
      },
      "source": [
        "rows = []\n",
        "p_dir = \"./\"\n",
        "parent_dir =p_dir +\"SWH-05-20101106\"\n",
        "files = os.listdir(parent_dir)\n",
        "for f in files:\n",
        "    audio, fs = librosa.load(f\"{parent_dir}/{f}\")\n",
        "    filename = f.split('.')[0]\n",
        "    row = {'filename': filename, 'audio': audio}\n",
        "    rows.append(row)\n",
        "rows[:5]\n",
        "\n",
        "# for filename in glob.glob(os.path.join(p_dir,'*','*.wav')):\n",
        "#     audio, fs = librosa.load(f\"{filename}\")\n",
        "#     filename = f.split('.')[0]\n",
        "#     row = {'filename': filename, 'audio': audio}\n",
        "#     rows.append(row)\n",
        "# rows[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part28',\n",
              "  'audio': array([-0.03379978, -0.03822443, -0.03214817, ..., -0.16410704,\n",
              "         -0.17117754, -0.1036144 ], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part182',\n",
              "  'audio': array([ 0.002242  ,  0.00087491, -0.00296297, ..., -0.18095487,\n",
              "         -0.13124813,  0.        ], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part139',\n",
              "  'audio': array([0.00549206, 0.0058774 , 0.00441616, ..., 0.0360385 , 0.02359483,\n",
              "         0.00684485], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part180',\n",
              "  'audio': array([-0.01427129, -0.01713051, -0.0142272 , ..., -0.12489323,\n",
              "         -0.08557392,  0.        ], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part156',\n",
              "  'audio': array([-0.0446428 , -0.0511893 , -0.036221  , ...,  0.15283288,\n",
              "          0.10397086,  0.        ], dtype=float32)}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeGMXkLWJ4np",
        "outputId": "138fe570-864d-49be-ae5d-39a371501695"
      },
      "source": [
        "len(files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8NByqTOUhRd",
        "outputId": "10d925a3-ec16-4087-974d-e24f41e7e08a"
      },
      "source": [
        "sample_audios = []\n",
        "for row in rows:\n",
        "    audio = row['audio']\n",
        "    sample_audios.append(audio)\n",
        "sample_audios[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.03379978, -0.03822443, -0.03214817, ..., -0.16410704,\n",
              "        -0.17117754, -0.1036144 ], dtype=float32),\n",
              " array([ 0.002242  ,  0.00087491, -0.00296297, ..., -0.18095487,\n",
              "        -0.13124813,  0.        ], dtype=float32),\n",
              " array([0.00549206, 0.0058774 , 0.00441616, ..., 0.0360385 , 0.02359483,\n",
              "        0.00684485], dtype=float32),\n",
              " array([-0.01427129, -0.01713051, -0.0142272 , ..., -0.12489323,\n",
              "        -0.08557392,  0.        ], dtype=float32),\n",
              " array([-0.0446428 , -0.0511893 , -0.036221  , ...,  0.15283288,\n",
              "         0.10397086,  0.        ], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H6faM08QvZ2"
      },
      "source": [
        "meta_df = pd.read_csv('/content/drive/MyDrive/Swahili/metadata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "bVVnaH5DT6DG",
        "outputId": "6ccfc426-88b8-43c9-9fc0-1193a65a8688"
      },
      "source": [
        "meta_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            filename  \\\n",
              "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
              "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
              "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
              "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
              "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
              "\n",
              "                                       transcription  \\\n",
              "0             rais wa tanzania jakaya mrisho kikwete   \n",
              "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...   \n",
              "2  inayokutangazia moja kwa moja kutoka jijini da...   \n",
              "3  juma hili bara la afrika limeshuhudia raia wa ...   \n",
              "4    wakipiga kura ya maoni ilikufanya mabadiliko ya   \n",
              "\n",
              "                                            filepath  sample_rate  duration  \n",
              "0  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.14  \n",
              "1  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.10  \n",
              "2  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.65  \n",
              "3  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.90  \n",
              "4  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      2.94  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-519d676e-e1bb-4f4c-a3cf-ec13f5d7db03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>transcription</th>\n",
              "      <th>filepath</th>\n",
              "      <th>sample_rate</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>3.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
              "      <td>16000</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-519d676e-e1bb-4f4c-a3cf-ec13f5d7db03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-519d676e-e1bb-4f4c-a3cf-ec13f5d7db03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-519d676e-e1bb-4f4c-a3cf-ec13f5d7db03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNHLp5mHSXbT",
        "outputId": "1e259c01-2439-489a-a64d-d66943ca1a65"
      },
      "source": [
        "txts = []\n",
        "for row in rows:\n",
        "    filename = row['filename']\n",
        "    filter = meta_df[meta_df['filename'] == filename]\n",
        "    txt = filter[['transcription']].values\n",
        "    txts.append(txt)\n",
        "\n",
        "txts[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([['kutoka viwanja vya uhuru hapa nchini tanzania']], dtype=object),\n",
              " array([['watanzania watarajie nini wapiga kura wana matarajio makubwa sana na wabunge wao']],\n",
              "       dtype=object),\n",
              " array([['ndiyo imekuwa dosari kubwa inaotajwa kutokea']], dtype=object),\n",
              " array([['kuwa tuna watuma yaani kile tunachotaka wakifanye']],\n",
              "       dtype=object),\n",
              " array([['hadi sasa inaridhisha <UNK>']], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtbOxUt-Vvzr"
      },
      "source": [
        "txts = np.array(txts).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdRmO_PMWK7M",
        "outputId": "20fba1f0-a711-40cb-b181-6304e3420e4f"
      },
      "source": [
        "txts[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['kutoka viwanja vya uhuru hapa nchini tanzania',\n",
              "       'watanzania watarajie nini wapiga kura wana matarajio makubwa sana na wabunge wao',\n",
              "       'ndiyo imekuwa dosari kubwa inaotajwa kutokea',\n",
              "       'kuwa tuna watuma yaani kile tunachotaka wakifanye',\n",
              "       'hadi sasa inaridhisha <UNK>'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj7dp_XDZFpb"
      },
      "source": [
        "clean_txts = []\n",
        "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
        "for txt in txts:\n",
        "    clean_txt = []\n",
        "    for c in txt:\n",
        "        if c not in alphabets and c != ' ':\n",
        "            continue\n",
        "        clean_txt.append(c)\n",
        "    clean_txt = ''.join(clean_txt)\n",
        "    clean_txts.append(clean_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hssO43laaId0",
        "outputId": "6fc57686-25e1-4f13-84d2-9cebfdd74376"
      },
      "source": [
        "clean_txts[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kutoka viwanja vya uhuru hapa nchini tanzania',\n",
              " 'watanzania watarajie nini wapiga kura wana matarajio makubwa sana na wabunge wao',\n",
              " 'ndiyo imekuwa dosari kubwa inaotajwa kutokea',\n",
              " 'kuwa tuna watuma yaani kile tunachotaka wakifanye',\n",
              " 'hadi sasa inaridhisha ']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY06jQ-lXfod",
        "outputId": "a6dc4160-a63f-4cd5-d122-7abeeff19a1f"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "keV4RInJXkY7",
        "outputId": "3735ad01-5acf-4722-b7a1-1ac0bdb8cdec"
      },
      "source": [
        "df = pd.DataFrame(clean_txts)\n",
        "df.columns = ['texts']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               texts\n",
              "0      kutoka viwanja vya uhuru hapa nchini tanzania\n",
              "1  watanzania watarajie nini wapiga kura wana mat...\n",
              "2       ndiyo imekuwa dosari kubwa inaotajwa kutokea\n",
              "3  kuwa tuna watuma yaani kile tunachotaka wakifanye\n",
              "4                             hadi sasa inaridhisha "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd3f7284-6149-43ed-a321-41b715a6f91a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kutoka viwanja vya uhuru hapa nchini tanzania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>watanzania watarajie nini wapiga kura wana mat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ndiyo imekuwa dosari kubwa inaotajwa kutokea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kuwa tuna watuma yaani kile tunachotaka wakifanye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hadi sasa inaridhisha</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd3f7284-6149-43ed-a321-41b715a6f91a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd3f7284-6149-43ed-a321-41b715a6f91a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd3f7284-6149-43ed-a321-41b715a6f91a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoqxUW6XXoPi",
        "outputId": "a691ca54-e8ad-4748-892b-010dce7a8814"
      },
      "source": [
        "idxs = df[df['texts'] == ''].index\n",
        "idxs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([49, 91, 123], dtype='int64')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcn64fCTXrJK"
      },
      "source": [
        "del clean_txts[idxs[-1]]\n",
        "del clean_txts[idxs[-2]]\n",
        "del clean_txts[idxs[-3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL0HfjOtXtxT",
        "outputId": "c62e209f-b716-446b-edf1-d9adc0f69713"
      },
      "source": [
        "'' in clean_txts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LofBDpPvXxLg"
      },
      "source": [
        "del sample_audios[idxs[-1]]\n",
        "del sample_audios[idxs[-2]]\n",
        "del sample_audios[idxs[-3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Aa-Wdc7Rnq"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30NG8Jgz1H56"
      },
      "source": [
        "def character_dict():\n",
        "    alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
        "    supported = alphabet.split()\n",
        "\n",
        "    char_map = {}\n",
        "    char_map[\"\"] = 0\n",
        "    char_map[\"<SPACE>\"] = 1\n",
        "    idx = 2\n",
        "    for c in supported:\n",
        "        char_map[c] = idx\n",
        "        idx += 1\n",
        "    index_map = {v: k for k, v in char_map.items()}\n",
        "    return char_map, index_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfjpMjZYU6nj"
      },
      "source": [
        "char_map, index_map = character_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMCrhqBSU6nk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73d0115-10bc-4bc1-f658-c247911a18f0"
      },
      "source": [
        "char_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '<SPACE>': 1,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'c': 4,\n",
              " 'd': 5,\n",
              " 'e': 6,\n",
              " 'f': 7,\n",
              " 'g': 8,\n",
              " 'h': 9,\n",
              " 'i': 10,\n",
              " 'j': 11,\n",
              " 'k': 12,\n",
              " 'l': 13,\n",
              " 'm': 14,\n",
              " 'n': 15,\n",
              " 'o': 16,\n",
              " 'p': 17,\n",
              " 'q': 18,\n",
              " 'r': 19,\n",
              " 's': 20,\n",
              " 't': 21,\n",
              " 'u': 22,\n",
              " 'v': 23,\n",
              " 'w': 24,\n",
              " 'x': 25,\n",
              " 'y': 26,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9nJ78TV8X-b"
      },
      "source": [
        "def text_to_int_sequence(text):\n",
        "    \"\"\" Convert text to an integer sequence \"\"\"\n",
        "    int_sequence = []\n",
        "    for c in text:\n",
        "        if c == ' ':\n",
        "            ch = char_map['<SPACE>']\n",
        "        elif c in alphabets:\n",
        "            ch = char_map[c]\n",
        "        else:\n",
        "            print(c)\n",
        "            print('character not found')\n",
        "            break\n",
        "        int_sequence.append(ch)\n",
        "    return np.array(int_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y39Q5Bq6frJ"
      },
      "source": [
        "def int_sequence_to_text(int_sequence):\n",
        "    \"\"\" Convert an integer sequence to text \"\"\"\n",
        "    textch = []\n",
        "    for c in int_sequence:\n",
        "        ch = index_map[c]\n",
        "        textch.append(ch)\n",
        "    text = ''.join(textch)\n",
        "    text = text.replace('<SPACE>', ' ')\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmvz_Svx7U7l"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, audios, texts, batch_size=32):\n",
        "        self.audios = audios\n",
        "        self.texts = texts\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = int(len(self.audios) // self.batch_size)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(self.steps*self.batch_size)\n",
        "        # np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\n",
        "    \n",
        "        batch_audios = [self.audios[int(i)] for i in indexes]\n",
        "        batch_texts = [self.texts[int(i)] for i in indexes]\n",
        "        \n",
        "        return  self.data_generation(batch_audios, batch_texts)\n",
        "    \n",
        "    def data_generation(self, batch_audios, batch_texts):\n",
        "\n",
        "        longest_audio = max([len(i) for i in batch_audios])\n",
        "        longest_txt = max([len(i) for i in batch_texts])\n",
        "\n",
        "        audios          = np.zeros([int(self.batch_size), longest_audio], dtype=\"float32\")\n",
        "        txts            = np.zeros([int(self.batch_size), longest_txt], dtype=\"int64\")\n",
        "        audio_length    = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "        txt_length      = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
        "\n",
        "        i = 0\n",
        "        for audio, txt in zip(batch_audios, batch_texts):\n",
        "\n",
        "            txt_len = len(txt)\n",
        "\n",
        "            txt = text_to_int_sequence(txt)\n",
        "       \n",
        "            txts[i,: txt_len] = txt\n",
        "\n",
        "            audio_len = len(audio)\n",
        "\n",
        "            audios[i, :audio_len] = audio\n",
        "\n",
        "            audio_length[i] = audio_len\n",
        "            txt_length[i] = txt_len\n",
        "\n",
        "            i+=1          \n",
        "            \n",
        "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
        "        inputs = {\n",
        "                    'the_input':    tf.convert_to_tensor(audios), \n",
        "                    'the_labels':   tf.convert_to_tensor(txts), \n",
        "                    'input_length': tf.convert_to_tensor(audio_length), \n",
        "                    'label_length': tf.convert_to_tensor(txt_length)\n",
        "                }\n",
        "        return (inputs, outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMZLj1GeQny1"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9yv2uTEBcWp",
        "outputId": "fbf30dd7-eeb3-4274-9521-c91d44a47a43"
      },
      "source": [
        "len(dg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F9PAObyKKNM",
        "outputId": "356af5d8-696c-45a9-e7e6-64a1ed4b97ca"
      },
      "source": [
        "dg[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'the_input': <tf.Tensor: shape=(32, 135387), dtype=float32, numpy=\n",
              "  array([[-0.00909726, -0.01020271, -0.00806536, ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [-0.00962744, -0.00908791, -0.0040448 , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.0063101 ,  0.00703578,  0.0055557 , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         ...,\n",
              "         [-0.00993562, -0.01121048, -0.00931332, ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.0015532 ,  0.00214485,  0.0019096 , ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.00304882,  0.00447894,  0.0048337 , ...,  0.        ,\n",
              "           0.        ,  0.        ]], dtype=float32)>,\n",
              "  'the_labels': <tf.Tensor: shape=(32, 112), dtype=int64, numpy=\n",
              "  array([[11,  6, 11, ...,  0,  0,  0],\n",
              "         [ 9,  2, 12, ...,  0,  0,  0],\n",
              "         [10,  5,  9, ...,  0,  0,  0],\n",
              "         ...,\n",
              "         [13,  2,  1, ...,  0,  0,  0],\n",
              "         [15,  2,  1, ...,  0,  0,  0],\n",
              "         [ 9, 22, 24, ...,  0,  0,  0]])>,\n",
              "  'input_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              "  array([109589,  50054,  85113, 124803,  60417,  69899,  49391, 108266,\n",
              "          54023,  82028,  72545,  62842,  51158, 110030,  53361, 102974,\n",
              "         108486,  53361,  62402,  80483,  78278,  70560, 116865,  47628,\n",
              "          58653,  71663, 135387,  69017,  70781,  69899,  98564,  74529])>,\n",
              "  'label_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
              "  array([ 60,  49,  59,  88,  38,  61,  30,  90,  38,  62,  42,  39,  53,\n",
              "          81,  62,  90,  74,  49,  38,  66,  44,  56, 112,  25,  52,  42,\n",
              "         100,  40,  45,  62,  66,  61])>},\n",
              " {'ctc': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])})"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2V8FZlhWdIt"
      },
      "source": [
        "batch1 = dg[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvPWc-V09v-c",
        "outputId": "a1f86a90-ee10-4aea-eba3-455d06bc443f"
      },
      "source": [
        "batch1['the_labels']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 116), dtype=int64, numpy=\n",
              "array([[12, 22, 21, ...,  0,  0,  0],\n",
              "       [24,  2, 21, ...,  0,  0,  0],\n",
              "       [15,  5, 10, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [12,  2, 27, ...,  0,  0,  0],\n",
              "       [11,  2, 12, ...,  0,  0,  0],\n",
              "       [12, 24,  2, ...,  0,  0,  0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qL0X05E9cit",
        "outputId": "4badb5c3-9acf-4068-a37f-b0ec26769d44"
      },
      "source": [
        "batch1['the_input']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 123700), dtype=float32, numpy=\n",
              "array([[-0.03379978, -0.03822443, -0.03214817, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.002242  ,  0.00087491, -0.00296297, ..., -0.18095487,\n",
              "        -0.13124813,  0.        ],\n",
              "       [ 0.00549206,  0.0058774 ,  0.00441616, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [-0.03675308, -0.04571614, -0.03824458, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.00065874, -0.00252594, -0.00411112, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.00060241, -0.00034816, -0.00233458, ...,  0.        ,\n",
              "         0.        ,  0.        ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C5AAUQvbiyk"
      },
      "source": [
        "### ctc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQIvrmyvjW13"
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnn6WhlZ4HJr"
      },
      "source": [
        "def input_lengths_lambda_func(args):\n",
        "    input_length = args\n",
        "    return tf.cast(tf.math.floor(input_length/hop_size)-1, dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdD6eacRjLtx"
      },
      "source": [
        "def add_ctc_loss(model_builder):\n",
        "    the_labels      = Input(name='the_labels',      shape=(None,), dtype='float32')\n",
        "    input_lengths   = Input(name='input_length',    shape=(1,), dtype='float32')\n",
        "    label_lengths   = Input(name='label_length',    shape=(1,), dtype='float32')\n",
        "\n",
        "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\n",
        "    if model_builder.output_length:\n",
        "         output_lengths  = Lambda(model_builder.output_length)(input_lengths2)\n",
        "    else:\n",
        "         output_lengths  = input_lengths2\n",
        "    \n",
        "    # CTC loss is implemented in a lambda layer\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model_builder.output, the_labels, output_lengths, label_lengths])\n",
        "    model = Model( inputs=[model_builder.input, the_labels, input_lengths, label_lengths],  outputs=loss_out)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdGaA4MTU6nx"
      },
      "source": [
        "## LogMelSpectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0lSFc5roaSe"
      },
      "source": [
        "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
        "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
        "                 f_min=0.0, f_max=None, **kwargs):\n",
        "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.fft_size = fft_size\n",
        "        self.hop_size = hop_size\n",
        "        self.n_mels = n_mels\n",
        "        self.f_min = f_min\n",
        "        self.f_max = f_max if f_max else sample_rate / 2\n",
        "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
        "            num_mel_bins=self.n_mels,\n",
        "            num_spectrogram_bins=fft_size // 2 + 1,\n",
        "            sample_rate=self.sample_rate,\n",
        "            lower_edge_hertz=self.f_min,\n",
        "            upper_edge_hertz=self.f_max)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.non_trainable_weights.append(self.mel_filterbank)\n",
        "        super(LogMelSpectrogram, self).build(input_shape)\n",
        "\n",
        "    def call(self, waveforms):\n",
        "        \"\"\"Forward pass.\n",
        "        Parameters\n",
        "        ----------\n",
        "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
        "            A Batch of mono waveforms.\n",
        "        Returns\n",
        "        -------\n",
        "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
        "            The corresponding batch of log-mel-spectrograms\n",
        "        \"\"\"\n",
        "        def _tf_log10(x):\n",
        "            numerator = tf.math.log(x)\n",
        "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
        "            return numerator / denominator\n",
        "\n",
        "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
        "            \"\"\"\n",
        "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
        "            \"\"\"\n",
        "            ref_value = tf.reduce_max(magnitude)\n",
        "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
        "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
        "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
        "\n",
        "            return log_spec\n",
        "\n",
        "        spectrograms = tf.signal.stft(waveforms,\n",
        "                                      frame_length=self.fft_size,\n",
        "                                      frame_step=self.hop_size,\n",
        "                                      pad_end=False)\n",
        "\n",
        "        magnitude_spectrograms = tf.abs(spectrograms)\n",
        "\n",
        "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
        "                                     self.mel_filterbank)\n",
        "\n",
        "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
        "\n",
        "        # add channel dimension\n",
        "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
        "\n",
        "        return log_mel_spectrograms\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'fft_size': self.fft_size,\n",
        "            'hop_size': self.hop_size,\n",
        "            'n_mels': self.n_mels,\n",
        "            'sample_rate': self.sample_rate,\n",
        "            'f_min': self.f_min,\n",
        "            'f_max': self.f_max,\n",
        "        }\n",
        "        config.update(super(LogMelSpectrogram, self).get_config())\n",
        "\n",
        "        return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxIVBU1NkAX5"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38567d3a"
      },
      "source": [
        "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
        "\n",
        "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
        "    featLayer = LogMelSpectrogram(\n",
        "        fft_size=fft_size,\n",
        "        hop_size=frame_step,\n",
        "        n_mels=n_mels,\n",
        "        \n",
        "        sample_rate=sample_rate,\n",
        "        f_min=0.0,\n",
        "        \n",
        "        f_max=int(sample_rate / 2)\n",
        "    )(input_data)\n",
        "    \n",
        "    x = BatchNormalization()(featLayer)\n",
        "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fa7b082"
      },
      "source": [
        "def simple_rnn_model(input_dim, output_dim=224):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    simp_rnn = GRU(output_dim, return_sequences=True,\n",
        "                   implementation=2, name='rnn')(input_data)\n",
        "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
        "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\n",
        "    model.output_length = lambda x: x\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBW9WjFwDWxW"
      },
      "source": [
        "def BidirectionalRNN(input_dim, rnn_layers=2, units=400, drop_out=0.5, act='tanh', output_dim=224):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(\n",
        "        None, input_dim))\n",
        "\n",
        "    x = Bidirectional(LSTM(units,  activation=act,\n",
        "                      return_sequences=True, implementation=2))(input_data)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(drop_out)(x)\n",
        "\n",
        "    for i in range(rnn_layers - 2):\n",
        "        x = Bidirectional(\n",
        "            LSTM(units, activation=act, return_sequences=True))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(drop_out)(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(units,  activation=act,\n",
        "                      return_sequences=True, implementation=2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(drop_out)(x)\n",
        "\n",
        "    time_dense = TimeDistributed(Dense(output_dim))(x)\n",
        "\n",
        "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
        "\n",
        "    model = Model(inputs=input_data, outputs=y_pred, name=\"BidirectionalRNN\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWc7n6yF5QKe"
      },
      "source": [
        "def conv_rnn(n_mels, output_dim=224, rnn_layers=4, units=400, drop_out=0.5, act='tanh'):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, n_mels, 1))\n",
        "\n",
        "    y = Conv2D(32, (3, 3), padding='same')(input_data)  # was 32\n",
        "    y = Activation('relu')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "\n",
        "    x = MaxPooling2D((1, 2))(y)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(y)  # was 32\n",
        "    x = Activation('relu')(x)\n",
        "    y = BatchNormalization()(y)\n",
        "\n",
        "    x = MaxPooling2D((1, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    y = BatchNormalization()(y)\n",
        "\n",
        "    x = MaxPooling2D((1, 2))(x)\n",
        "\n",
        "    x = Dense(128)(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = Dense(32)(x)\n",
        "\n",
        "    x = Reshape((-1, x.shape[-1] * x.shape[-2]))(x)\n",
        "\n",
        "    for i in range(rnn_layers):\n",
        "        x = Bidirectional(\n",
        "            LSTM(units, activation=act, return_sequences=True))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(drop_out)(x)\n",
        "\n",
        "    bn_rnn = BatchNormalization()(x)\n",
        "\n",
        "    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn)\n",
        "\n",
        "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
        "\n",
        "    model = Model(inputs=input_data, outputs=y_pred, name=\"custom_model\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ae84266"
      },
      "source": [
        "def train(model_builder, \n",
        "          data_gen,\n",
        "          epochs, \n",
        "          verbose=1,\n",
        "          optimizer=SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
        "          ):    \n",
        "              \n",
        "    model = add_ctc_loss(model_builder)\n",
        "\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
        "    print(model.summary())\n",
        "\n",
        "    # add checkpointer\n",
        "    checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5', verbose=1)\n",
        "    early_stopping = EarlyStopping( monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "\n",
        "    hist = model.fit_generator(generator=data_gen,\n",
        "                               epochs=epochs,\n",
        "                               callbacks=[checkpointer, early_stopping], \n",
        "                               verbose=verbose, \n",
        "                               use_multiprocessing=False)\n",
        "    \n",
        "    # save model loss\n",
        "    with open('/content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn.pickle', 'wb') as f:\n",
        "        pickle.dump(hist.history, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEC6FFW_kayX"
      },
      "source": [
        "### Trainig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa980211"
      },
      "source": [
        "\n",
        "sample_rate = 22050\n",
        "fft_size = 1024\n",
        "frame_step = 512\n",
        "n_mels = 128\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "data_len = len(clean_txts)\n",
        "output_dim = len(char_map) + 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a97ffc77"
      },
      "source": [
        "dg = DataGenerator(sample_audios, clean_txts, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68e9985a",
        "outputId": "3479f712-9f48-4874-8af9-fcb1b8fd2c59"
      },
      "source": [
        "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\n",
        "preprocess_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"preprocessin_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, None)]            0         \n",
            "                                                                 \n",
            " log_mel_spectrogram_4 (LogM  (None, None, 128, 1)     0         \n",
            " elSpectrogram)                                                  \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, None, 128, 1)     4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 2\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b8711e1",
        "outputId": "3ed78ecb-8543-4e0b-eee1-2a1438507a6d"
      },
      "source": [
        "speech_model = conv_rnn(n_mels, output_dim = output_dim)\n",
        "speech_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"custom_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " the_input (InputLayer)      [(None, None, 128, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, None, 128, 32)     320       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, None, 128, 32)     0         \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, None, 128, 32)    128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, None, 128, 64)     18496     \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, None, 128, 64)     0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, None, 64, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, None, 64, 128)     73856     \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, None, 64, 128)     0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, None, 32, 128)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, None, 32, 128)     16512     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, None, 32, 64)      8256      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, None, 32, 32)      2080      \n",
            "                                                                 \n",
            " reshape_4 (Reshape)         (None, None, 1024)        0         \n",
            "                                                                 \n",
            " bidirectional_16 (Bidirecti  (None, None, 800)        4560000   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, None, 800)        3200      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, None, 800)         0         \n",
            "                                                                 \n",
            " bidirectional_17 (Bidirecti  (None, None, 800)        3843200   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, None, 800)        3200      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, None, 800)         0         \n",
            "                                                                 \n",
            " bidirectional_18 (Bidirecti  (None, None, 800)        3843200   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, None, 800)        3200      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, None, 800)         0         \n",
            "                                                                 \n",
            " bidirectional_19 (Bidirecti  (None, None, 800)        3843200   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, None, 800)        3200      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, None, 800)         0         \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, None, 800)        3200      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, None, 30)         24030     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " softmax (Activation)        (None, None, 30)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,249,278\n",
            "Trainable params: 16,241,214\n",
            "Non-trainable params: 8,064\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62f39784"
      },
      "source": [
        "def build_model(output_dim, custom_model, preprocess_model, calc=None):\n",
        "\n",
        "    input_audios = Input(name='the_input', shape=(None,))\n",
        "    pre = preprocess_model(input_audios)\n",
        "    pre = tf.squeeze(pre, [3])\n",
        "\n",
        "    y_pred = custom_model(pre)\n",
        "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
        "    model.output_length = calc\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35985dd6",
        "outputId": "346b30c0-368e-47ca-d80e-865ba8a666f3"
      },
      "source": [
        "model = build_model(output_dim, speech_model, preprocess_model)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_builder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " the_input (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " preprocessin_model (Functio  (None, None, 128, 1)     4         \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " tf.compat.v1.squeeze_4 (TFO  (None, None, 128)        0         \n",
            " pLambda)                                                        \n",
            "                                                                 \n",
            " custom_model (Functional)   (None, None, 30)          16249278  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,249,282\n",
            "Trainable params: 16,241,216\n",
            "Non-trainable params: 8,066\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "hf = h5py.File('/content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5', 'w')\n",
        "hf.close()"
      ],
      "metadata": {
        "id": "DuUnCuIfm-nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvrVqeu8FvgQ"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5', by_name = True, skip_mismatch = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N38b7Grd3zXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f64498-d43b-4a16-8655-70f701f59224"
      },
      "source": [
        " !pip install mlflow --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     || 17.0 MB 14.5 MB/s \n",
            "\u001b[K     || 77 kB 7.4 MB/s \n",
            "\u001b[K     || 209 kB 63.6 MB/s \n",
            "\u001b[K     || 182 kB 70.7 MB/s \n",
            "\u001b[K     || 147 kB 56.4 MB/s \n",
            "\u001b[K     || 79 kB 9.2 MB/s \n",
            "\u001b[K     || 78 kB 7.8 MB/s \n",
            "\u001b[K     || 55 kB 3.0 MB/s \n",
            "\u001b[K     || 140 kB 51.3 MB/s \n",
            "\u001b[K     || 62 kB 1.4 MB/s \n",
            "\u001b[K     || 62 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6b2a7e2"
      },
      "source": [
        " import mlflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea406859",
        "outputId": "a5540c14-e1c3-4a0c-ac77-2da368014496"
      },
      "source": [
        "# mlflow.set_experiment('Speech Model-RNN-baseline')\n",
        "# mlflow.tensorflow.autolog()\n",
        "hop_size = 512\n",
        "train(model, dg, epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " the_input (InputLayer)         [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " preprocessin_model (Functional  (None, None, 128, 1  4          ['the_input[0][0]']              \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze_4 (TFOpLa  (None, None, 128)   0           ['preprocessin_model[0][0]']     \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " custom_model (Functional)      (None, None, 30)     16249278    ['tf.compat.v1.squeeze_4[0][0]'] \n",
            "                                                                                                  \n",
            " the_labels (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1)            0           ['input_length[0][0]']           \n",
            "                                                                                                  \n",
            " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ctc (Lambda)                   (None, 1)            0           ['custom_model[0][0]',           \n",
            "                                                                  'the_labels[0][0]',             \n",
            "                                                                  'lambda[0][0]',                 \n",
            "                                                                  'label_length[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,249,282\n",
            "Trainable params: 16,241,216\n",
            "Non-trainable params: 8,066\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - ETA: 0s - loss: 286.8180\n",
            "Epoch 1: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 46s 2s/step - loss: 286.8180\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 195.5413\n",
            "Epoch 2: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 5s 821ms/step - loss: 195.5413\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 183.9459\n",
            "Epoch 3: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 654ms/step - loss: 183.9459\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 173.7718\n",
            "Epoch 4: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 660ms/step - loss: 173.7718\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 166.4625\n",
            "Epoch 5: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 661ms/step - loss: 166.4625\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 163.8469\n",
            "Epoch 6: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 684ms/step - loss: 163.8469\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 158.9009\n",
            "Epoch 7: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 664ms/step - loss: 158.9009\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 156.1902\n",
            "Epoch 8: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 668ms/step - loss: 156.1902\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 152.7942\n",
            "Epoch 9: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 666ms/step - loss: 152.7942\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 152.1701\n",
            "Epoch 10: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 664ms/step - loss: 152.1701\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 148.9795\n",
            "Epoch 11: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 701ms/step - loss: 148.9795\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 151.2951\n",
            "Epoch 12: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 698ms/step - loss: 151.2951\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 146.9511\n",
            "Epoch 13: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 659ms/step - loss: 146.9511\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 144.9423\n",
            "Epoch 14: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 666ms/step - loss: 144.9423\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 142.4432\n",
            "Epoch 15: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 651ms/step - loss: 142.4432\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 142.5660\n",
            "Epoch 16: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 654ms/step - loss: 142.5660\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 140.0753\n",
            "Epoch 17: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 651ms/step - loss: 140.0753\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 138.6096\n",
            "Epoch 18: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 659ms/step - loss: 138.6096\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 135.7240\n",
            "Epoch 19: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 649ms/step - loss: 135.7240\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 134.0663\n",
            "Epoch 20: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 660ms/step - loss: 134.0663\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 132.1957\n",
            "Epoch 21: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 747ms/step - loss: 132.1957\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 131.7331\n",
            "Epoch 22: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 660ms/step - loss: 131.7331\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 129.2185\n",
            "Epoch 23: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 664ms/step - loss: 129.2185\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 127.5054\n",
            "Epoch 24: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 668ms/step - loss: 127.5054\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 126.1824\n",
            "Epoch 25: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 126.1824\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 123.8894\n",
            "Epoch 26: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 670ms/step - loss: 123.8894\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 122.5667\n",
            "Epoch 27: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 656ms/step - loss: 122.5667\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 120.8020\n",
            "Epoch 28: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 656ms/step - loss: 120.8020\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 118.8193\n",
            "Epoch 29: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 651ms/step - loss: 118.8193\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 116.6696\n",
            "Epoch 30: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 652ms/step - loss: 116.6696\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 115.2640\n",
            "Epoch 31: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 665ms/step - loss: 115.2640\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 114.1032\n",
            "Epoch 32: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 648ms/step - loss: 114.1032\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 111.5277\n",
            "Epoch 33: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 663ms/step - loss: 111.5277\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 109.4235\n",
            "Epoch 34: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 651ms/step - loss: 109.4235\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 108.1992\n",
            "Epoch 35: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 709ms/step - loss: 108.1992\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 107.1970\n",
            "Epoch 36: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 107.1970\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 104.8472\n",
            "Epoch 37: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 657ms/step - loss: 104.8472\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 104.5202\n",
            "Epoch 38: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 682ms/step - loss: 104.5202\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 101.8138\n",
            "Epoch 39: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 697ms/step - loss: 101.8138\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 99.7690\n",
            "Epoch 40: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 656ms/step - loss: 99.7690\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 99.0702 \n",
            "Epoch 41: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 662ms/step - loss: 99.0702\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 96.9231\n",
            "Epoch 42: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 96.9231\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 96.2451\n",
            "Epoch 43: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 691ms/step - loss: 96.2451\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 94.3834\n",
            "Epoch 44: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 670ms/step - loss: 94.3834\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 93.3260\n",
            "Epoch 45: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 662ms/step - loss: 93.3260\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 91.6292\n",
            "Epoch 46: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 661ms/step - loss: 91.6292\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 89.9858\n",
            "Epoch 47: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 89.9858\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 89.1487\n",
            "Epoch 48: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 664ms/step - loss: 89.1487\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 88.2873\n",
            "Epoch 49: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 718ms/step - loss: 88.2873\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 85.9302\n",
            "Epoch 50: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 666ms/step - loss: 85.9302\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 84.3158\n",
            "Epoch 51: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 661ms/step - loss: 84.3158\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 83.9212\n",
            "Epoch 52: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 655ms/step - loss: 83.9212\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 82.4132\n",
            "Epoch 53: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 669ms/step - loss: 82.4132\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 81.3724\n",
            "Epoch 54: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 661ms/step - loss: 81.3724\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 79.8520\n",
            "Epoch 55: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 652ms/step - loss: 79.8520\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 78.5441\n",
            "Epoch 56: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 662ms/step - loss: 78.5441\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 76.9325\n",
            "Epoch 57: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 655ms/step - loss: 76.9325\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 76.8555\n",
            "Epoch 58: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 697ms/step - loss: 76.8555\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 74.7960\n",
            "Epoch 59: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 659ms/step - loss: 74.7960\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 73.4941\n",
            "Epoch 60: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 655ms/step - loss: 73.4941\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 72.7340\n",
            "Epoch 61: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 673ms/step - loss: 72.7340\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 71.8725\n",
            "Epoch 62: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 655ms/step - loss: 71.8725\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 70.1016\n",
            "Epoch 63: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 655ms/step - loss: 70.1016\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 69.7939\n",
            "Epoch 64: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 647ms/step - loss: 69.7939\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 68.2813\n",
            "Epoch 65: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 692ms/step - loss: 68.2813\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 66.7362\n",
            "Epoch 66: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 66.7362\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 65.5037\n",
            "Epoch 67: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 655ms/step - loss: 65.5037\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 65.3135\n",
            "Epoch 68: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 658ms/step - loss: 65.3135\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 64.4100\n",
            "Epoch 69: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 64.4100\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 62.6828\n",
            "Epoch 70: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 668ms/step - loss: 62.6828\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 62.5753\n",
            "Epoch 71: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 62.5753\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 61.1584\n",
            "Epoch 72: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 669ms/step - loss: 61.1584\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 59.9314\n",
            "Epoch 73: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 692ms/step - loss: 59.9314\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 59.1495\n",
            "Epoch 74: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 682ms/step - loss: 59.1495\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 57.9362\n",
            "Epoch 75: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 57.9362\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 57.5852\n",
            "Epoch 76: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 729ms/step - loss: 57.5852\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 56.3793\n",
            "Epoch 77: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 688ms/step - loss: 56.3793\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 55.4384\n",
            "Epoch 78: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 691ms/step - loss: 55.4384\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 54.6971\n",
            "Epoch 79: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 54.6971\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 53.5236\n",
            "Epoch 80: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 674ms/step - loss: 53.5236\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 53.0841\n",
            "Epoch 81: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 689ms/step - loss: 53.0841\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 52.0546\n",
            "Epoch 82: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 724ms/step - loss: 52.0546\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 51.3099\n",
            "Epoch 83: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 665ms/step - loss: 51.3099\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 50.4618\n",
            "Epoch 84: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 692ms/step - loss: 50.4618\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 50.5155\n",
            "Epoch 85: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 664ms/step - loss: 50.5155\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 49.7932\n",
            "Epoch 86: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 658ms/step - loss: 49.7932\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 48.9640\n",
            "Epoch 87: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 48.9640\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 46.2860\n",
            "Epoch 88: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 668ms/step - loss: 46.2860\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 47.2747\n",
            "Epoch 89: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 664ms/step - loss: 47.2747\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 45.9601\n",
            "Epoch 90: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 688ms/step - loss: 45.9601\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 45.8646\n",
            "Epoch 91: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 662ms/step - loss: 45.8646\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 45.4127\n",
            "Epoch 92: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 701ms/step - loss: 45.4127\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 44.8824\n",
            "Epoch 93: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 44.8824\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 43.9849\n",
            "Epoch 94: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 700ms/step - loss: 43.9849\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 42.7141\n",
            "Epoch 95: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 660ms/step - loss: 42.7141\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 42.0507\n",
            "Epoch 96: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 700ms/step - loss: 42.0507\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 41.8700\n",
            "Epoch 97: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 661ms/step - loss: 41.8700\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 41.3852\n",
            "Epoch 98: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 662ms/step - loss: 41.3852\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 40.5622\n",
            "Epoch 99: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 667ms/step - loss: 40.5622\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - ETA: 0s - loss: 40.7583\n",
            "Epoch 100: saving model to /content/drive/MyDrive/Swahili/data/train/Model/cnn_rnn3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 4s 679ms/step - loss: 40.7583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ZKNcVjcpB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e20f867-ec8e-4090-92e1-c51491e04f7e"
      },
      "source": [
        "!pip install jiwer --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     || 1.4 MB 20.5 MB/s \n",
            "\u001b[K     || 2.2 MB 52.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-1frHIJYv5k"
      },
      "source": [
        "from jiwer import wer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al0dtmT1YK0p"
      },
      "source": [
        "def predict(data_gen,  num_elem=1, index=0):\n",
        "    \n",
        "    pred_data = data_gen.__getitem__(index)\n",
        "\n",
        "    pred_audios = pred_data[0][\"the_input\"]\n",
        "    pred_labels = pred_data[0][\"the_labels\"]\n",
        "    \n",
        "    y_pred = model.predict(pred_audios)\n",
        "\n",
        "    input_shape = tf.keras.backend.shape(y_pred)\n",
        "    input_length = tf.ones(shape=input_shape[0]) * tf.keras.backend.cast(input_shape[1], 'float32')\n",
        "    prediction = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=False)[0][0]\n",
        "    \n",
        "\n",
        "    for i in range(0, num_elem):  # only on clean data\n",
        "        \n",
        "        pred = K.eval(prediction[i]).flatten().tolist()\n",
        "        pred = [i for i in pred if i != -1]\n",
        "\n",
        "\n",
        "\n",
        "        ground_truth = int_sequence_to_text(pred_labels[i].numpy())\n",
        "        hypothesis   = ''.join(int_sequence_to_text(pred))\n",
        "        # error        = wer(ground_truth, hypothesis)\n",
        "                \n",
        "        print('-'*48 + ' ' + str(i) + ' ' + '-'*48)\n",
        "        print('True transcription:\\n' + '\\n' + ground_truth)\n",
        "        print('-'*100)\n",
        "        print('Predicted transcription:\\n' + '\\n' + hypothesis)\n",
        "        # print('-'*100)\n",
        "        # print('Word Error Rate:' + str(error))\n",
        "        print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzC37XxWZH4o"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnS0XSnZSt_",
        "outputId": "96725116-ef21-4391-9eb1-b65bbf665f3c"
      },
      "source": [
        "rows1 = []\n",
        "parent_dir1 = \"./SWH-05-20101107\"\n",
        "files1 = os.listdir(parent_dir1)\n",
        "for f in files1:\n",
        "    audio, fs = librosa.load(f\"{parent_dir1}/{f}\")\n",
        "    filename = f.split('.')[0]\n",
        "    row = {'filename': filename, 'audio': audio}\n",
        "    rows1.append(row)\n",
        "rows1[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'filename': 'SWH-05-20101107_16k-emission_swahili_05h30_-_06h00_tu_20101107_part33',\n",
              "  'audio': array([0.00104321, 0.00165943, 0.00152614, ..., 0.03417829, 0.02824923,\n",
              "         0.01558879], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101107_16k-emission_swahili_05h30_-_06h00_tu_20101107_part170',\n",
              "  'audio': array([ 0.01966014,  0.00921181, -0.00616249, ...,  0.06976125,\n",
              "          0.05451657,  0.        ], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101107_16k-emission_swahili_05h30_-_06h00_tu_20101107_part158',\n",
              "  'audio': array([-0.00656853, -0.00695729, -0.00374735, ..., -0.10506113,\n",
              "         -0.12291247,  0.        ], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101107_16k-emission_swahili_05h30_-_06h00_tu_20101107_part3',\n",
              "  'audio': array([ 0.0008225 ,  0.00121391,  0.00155496, ..., -0.11234738,\n",
              "         -0.11032466, -0.06956042], dtype=float32)},\n",
              " {'filename': 'SWH-05-20101107_16k-emission_swahili_05h30_-_06h00_tu_20101107_part55',\n",
              "  'audio': array([0.01748345, 0.01829427, 0.01416619, ..., 0.06764735, 0.07200358,\n",
              "         0.04313861], dtype=float32)}]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm5CFcjsZSuH",
        "outputId": "5f2d0865-7105-441f-db55-7fc495d286e9"
      },
      "source": [
        "sample_audios1 = []\n",
        "for row in rows1:\n",
        "    audio = row['audio']\n",
        "    sample_audios1.append(audio)\n",
        "sample_audios1[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.00104321, 0.00165943, 0.00152614, ..., 0.03417829, 0.02824923,\n",
              "        0.01558879], dtype=float32),\n",
              " array([ 0.01966014,  0.00921181, -0.00616249, ...,  0.06976125,\n",
              "         0.05451657,  0.        ], dtype=float32),\n",
              " array([-0.00656853, -0.00695729, -0.00374735, ..., -0.10506113,\n",
              "        -0.12291247,  0.        ], dtype=float32),\n",
              " array([ 0.0008225 ,  0.00121391,  0.00155496, ..., -0.11234738,\n",
              "        -0.11032466, -0.06956042], dtype=float32),\n",
              " array([0.01748345, 0.01829427, 0.01416619, ..., 0.06764735, 0.07200358,\n",
              "        0.04313861], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8BBrDjBZSuJ"
      },
      "source": [
        "meta_df = pd.read_csv('/content/drive/MyDrive/Swahili/metadata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx8JWPEwZSuO",
        "outputId": "68c6354c-d282-421c-ac80-6680d7679990"
      },
      "source": [
        "txts1 = []\n",
        "for row in rows1:\n",
        "    filename = row['filename']\n",
        "    filter = meta_df[meta_df['filename'] == filename]\n",
        "    txt = filter[['transcription']].values\n",
        "    txts1.append(txt)\n",
        "\n",
        "txts1[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([['bi ingabire elize na diude hakizimana <music>']], dtype=object),\n",
              " array([['tuna maziwa tuna misitu tuna milima']], dtype=object),\n",
              " array([['kwa hivyo mama mwenye mtoto kukaa kituoni wakati anaona hawa wana pita pita']],\n",
              "       dtype=object),\n",
              " array([['habari za asubuhi ni jumapili ya tarehe saba ya mwezi novemba']],\n",
              "       dtype=object),\n",
              " array([['kaa tayari kusikiliza makala haya']], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft5U3nwAZSuR"
      },
      "source": [
        "txts1 = np.array(txts1).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvjcHFl8ZSuT",
        "outputId": "b6e8262d-f485-4e4a-f97f-b0c1df35b327"
      },
      "source": [
        "txts1[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['bi ingabire elize na diude hakizimana <music>',\n",
              "       'tuna maziwa tuna misitu tuna milima',\n",
              "       'kwa hivyo mama mwenye mtoto kukaa kituoni wakati anaona hawa wana pita pita',\n",
              "       'habari za asubuhi ni jumapili ya tarehe saba ya mwezi novemba',\n",
              "       'kaa tayari kusikiliza makala haya'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kFCM_27ZSuV"
      },
      "source": [
        "clean_txts1 = []\n",
        "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
        "for txt in txts1:\n",
        "    clean_txt = []\n",
        "    for c in txt:\n",
        "        if c not in alphabets and c != ' ':\n",
        "            continue\n",
        "        clean_txt.append(c)\n",
        "    clean_txt = ''.join(clean_txt)\n",
        "    clean_txts1.append(clean_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfIJMLzzZSuX",
        "outputId": "aa932edc-fe2a-437c-921c-870d055145bb"
      },
      "source": [
        "clean_txts1[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bi ingabire elize na diude hakizimana music',\n",
              " 'tuna maziwa tuna misitu tuna milima',\n",
              " 'kwa hivyo mama mwenye mtoto kukaa kituoni wakati anaona hawa wana pita pita',\n",
              " 'habari za asubuhi ni jumapili ya tarehe saba ya mwezi novemba',\n",
              " 'kaa tayari kusikiliza makala haya']"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRJv5vTLZSuZ",
        "outputId": "696d4e68-f0aa-4a83-f1ae-698d3e0f1e41"
      },
      "source": [
        "'' in clean_txts1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4JYiuMYaejv"
      },
      "source": [
        "dg1 = DataGenerator(sample_audios1[:5], clean_txts1[:5], 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F6q_hiEanxN",
        "outputId": "4ae56457-3ed3-4c21-cf9e-63ef252b4cca"
      },
      "source": [
        "predict(dg1, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "------------------------------------------------ 0 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "bi ingabire elize na diude hakizimana music\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "di i nalie hliliz i na jiegtenea kizi manaoaoa a a a a a\n",
            "\n",
            "\n",
            "------------------------------------------------ 1 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "tuna maziwa tuna misitu tuna milima\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "tunamazi wa kunamishi k kunandilimaoaoa a a a a a\n",
            "\n",
            "\n",
            "------------------------------------------------ 2 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "kwa hivyo mama mwenye mtoto kukaa kituoni wakati anaona hawa wana pita pita\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "a kwaliya ma mwa wanya mutoata kukwatituwali wa katanaowana wana kita kitza k\n",
            "\n",
            "\n",
            "------------------------------------------------ 3 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "habari za asubuhi ni jumapili ya tarehe saba ya mwezi novemba\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "khabari ka zashubu nun jumapi a tesaba gya mwezin a vemba\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Publish Model"
      ],
      "metadata": {
        "id": "Gss06SsWFOBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo apt-get install git-lfs\n",
        "!pip install transformers==4.23.1\n",
        "import transformers\n",
        "!transformers-cli login\n",
        "!transformers-cli repo ASR_model\n",
        "!git clone https://huggingface.co/Kiki2022/ASR_model\n",
        "!cd ASR_model\n",
        "!git lfs install\n",
        "# git clone https://huggingface.co/Kiki2022/ASR_model\n",
        "# sudo apt-get install git-lfs\n",
        "# cd Swa2Text\n",
        "# git lfs install\n",
        "# git config --global user.email alex.wamai@strathmore.edu\n",
        "# git config --global user.name Alex Wamai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDBvIlSA7VGp",
        "outputId": "babb55a9-9cfe-4ec9-b662-35506317df4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.23.1 in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (2.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.23.1) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.23.1) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.23.1) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.23.1) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.23.1) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.23.1) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.23.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.23.1) (1.26.13)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/transformers-cli\", line 5, in <module>\n",
            "    from transformers.commands.transformers_cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/commands/transformers_cli.py\", line 24, in <module>\n",
            "    from .pt_to_tf import PTtoTFCommand\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/commands/pt_to_tf.py\", line 21, in <module>\n",
            "    from datasets import load_dataset\n",
            "ModuleNotFoundError: No module named 'datasets'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/transformers-cli\", line 5, in <module>\n",
            "    from transformers.commands.transformers_cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/commands/transformers_cli.py\", line 24, in <module>\n",
            "    from .pt_to_tf import PTtoTFCommand\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/commands/pt_to_tf.py\", line 21, in <module>\n",
            "    from datasets import load_dataset\n",
            "ModuleNotFoundError: No module named 'datasets'\n",
            "fatal: destination path 'ASR_model' already exists and is not an empty directory.\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any parent up to mount point /content)\\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\\n\"\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    }
  ]
}